"""Shared command handling for room monitors."""

from __future__ import annotations

import asyncio
import dataclasses
import logging
import re
import time
from collections.abc import Awaitable, Callable
from datetime import datetime
from typing import Any, Protocol

from ..agentic_actor.actor import AgentResult
from ..providers import parse_model_spec
from ..rate_limiter import RateLimiter
from .autochronicler import AutoChronicler
from .message import RoomMessage
from .proactive import ProactiveDebouncer
from .resolver import CommandResolver, ResolvedCommand
from .steering_queue import SteeringKey, SteeringQueue

logger = logging.getLogger(__name__)

HELP_TOKEN = "!h"
FLAG_TOKENS = {"!c"}


class ResponseCleaner(Protocol):
    """Optional response cleanup hook."""

    def __call__(self, text: str, nick: str) -> str: ...


def model_str_core(model: Any) -> str:
    """Extract core model names: provider:namespace/model#routing -> model."""

    return re.sub(r"(?:[-\w]*:)?(?:[-\w]*/)?([-\w]+)(?:#[-\w,]*)?", r"\1", str(model))


def _deep_merge_config(base: dict[str, Any], override: dict[str, Any]) -> dict[str, Any]:
    result: dict[str, Any] = {}
    for key, value in base.items():
        if isinstance(value, dict):
            result[key] = _deep_merge_config(value, {})
        elif isinstance(value, list):
            result[key] = list(value)
        else:
            result[key] = value

    for key, value in override.items():
        if key == "ignore_users" and isinstance(value, list):
            base_list = result.get(key, [])
            result[key] = [*base_list, *value]
            continue
        if key == "prompt_vars" and isinstance(value, dict):
            base_vars = result.get(key, {})
            merged_vars = dict(base_vars)
            for var_key, var_value in value.items():
                if var_key in merged_vars and isinstance(var_value, str):
                    # Concatenate string values for the same key
                    merged_vars[var_key] = f"{merged_vars[var_key]}{var_value}"
                else:
                    merged_vars[var_key] = var_value
            result[key] = merged_vars
            continue
        if isinstance(value, dict) and isinstance(result.get(key), dict):
            result[key] = _deep_merge_config(result[key], value)
            continue
        if isinstance(value, list):
            result[key] = list(value)
            continue
        result[key] = value

    return result


def get_room_config(config: dict[str, Any], room_name: str) -> dict[str, Any]:
    """Get merged room config from common + room overrides."""

    rooms = config.get("rooms", {})
    common = rooms.get("common", {})
    room = rooms.get(room_name, {})
    return _deep_merge_config(common, room)


class RoomCommandHandler:
    """Shared command + proactive handling for rooms."""

    def __init__(
        self,
        agent: Any,
        room_name: str,
        room_config: dict[str, Any],
        response_cleaner: ResponseCleaner | None = None,
    ) -> None:
        self.agent = agent
        self.room_name = room_name
        self.room_config = room_config
        self.response_cleaner = response_cleaner

        command_config = self.room_config["command"]
        proactive_config = self.room_config["proactive"]

        self.command_resolver = CommandResolver(
            command_config,
            classify_mode=self.classify_mode,
            help_token=HELP_TOKEN,
            flag_tokens=FLAG_TOKENS,
            model_name_formatter=model_str_core,
        )

        self.rate_limiter = RateLimiter(command_config["rate_limit"], command_config["rate_period"])
        self.proactive_rate_limiter = RateLimiter(
            proactive_config["rate_limit"], proactive_config["rate_period"]
        )
        self.proactive_debouncer = ProactiveDebouncer(proactive_config["debounce_seconds"])
        self.autochronicler = AutoChronicler(self.agent.history, self)

        self.steering_queue = SteeringQueue()

    @property
    def command_config(self) -> dict[str, Any]:
        return self.room_config["command"]

    @property
    def proactive_config(self) -> dict[str, Any]:
        return self.room_config["proactive"]

    def _response_max_bytes(self) -> int:
        return int(self.command_config.get("response_max_bytes", 600))

    def _clean_response_text(self, response_text: str, nick: str) -> str:
        cleaned = response_text.strip()
        if self.response_cleaner:
            cleaned = self.response_cleaner(cleaned, nick)
        return cleaned.strip()

    def should_ignore_user(self, nick: str) -> bool:
        ignore_list = self.command_config.get("ignore_users", [])
        return any(nick.lower() == ignored.lower() for ignored in ignore_list)

    def build_system_prompt(self, mode: str, mynick: str, model_override: str | None = None) -> str:
        """Build a command system prompt with standard substitutions."""

        try:
            prompt_template = self.command_config["modes"][mode]["prompt"]
        except KeyError:
            raise ValueError(f"Command mode '{mode}' not found in config") from None

        modes_config = self.command_config["modes"]
        prompt_vars = self.room_config.get("prompt_vars", {})

        def model_var(value: Any) -> str:
            if isinstance(value, list):
                return model_str_core(value[0]) if value else ""
            return model_str_core(value)

        trigger_model_vars: dict[str, str] = {}
        for trigger, mode_key in self.command_resolver.trigger_to_mode.items():
            mode_cfg = modes_config[mode_key]
            trigger_model = self.command_resolver.trigger_overrides[trigger].get("model")
            if trigger_model is None:
                trigger_model = (
                    model_override if mode_key == mode and model_override else mode_cfg["model"]
                )
            trigger_model_vars[trigger] = model_var(trigger_model)

        def replace_trigger_model(match: re.Match[str]) -> str:
            trigger = match.group(1)
            if trigger not in trigger_model_vars:
                raise ValueError(
                    f"Prompt placeholder '{{{trigger}_model}}' references unknown trigger"
                )
            return trigger_model_vars[trigger]

        prompt_template = re.sub(
            r"\{(![A-Za-z][\w-]*)_model\}",
            replace_trigger_model,
            prompt_template,
        )

        return prompt_template.format(
            mynick=mynick,
            current_time=datetime.now().strftime("%Y-%m-%d %H:%M"),
            **prompt_vars,
        )

    async def classify_mode(self, context: list[dict[str, str]]) -> str:
        """Use preprocessing model to classify message mode."""

        try:
            if not context:
                raise ValueError(
                    "Context cannot be empty - must include at least the current message"
                )

            current_message = context[-1]["content"]

            # Clean message content if it has IRC nick formatting like "<nick> message"
            message_match = re.search(r"<[^>]+>\s*(.*)", current_message)
            if message_match:
                current_message = message_match.group(1).strip()

            prompt = self.command_config["mode_classifier"]["prompt"].format(
                message=current_message
            )
            model = self.command_config["mode_classifier"]["model"]
            resp, client, _, _ = await self.agent.model_router.call_raw_with_model(
                model, context, prompt
            )
            response = client.extract_text_from_response(resp)
            response_upper = response.upper()

            counts = {
                label: response_upper.count(label.upper())
                for label in self.command_resolver.classifier_label_to_trigger
            }
            best_label, best_count = max(counts.items(), key=lambda item: item[1])
            if best_count == 0:
                logger.warning("Invalid mode classification response: %s", response)
                return self.command_resolver.fallback_classifier_label
            return best_label
        except Exception as e:
            logger.error("Error classifying mode: %s", e)
            return self.command_resolver.fallback_classifier_label

    async def should_interject_proactively(
        self, context: list[dict[str, str]]
    ) -> tuple[bool, str, bool]:
        """Use preprocessing models to decide if bot should interject in conversation proactively.

        Args:
            context: Conversation context including the current message as the last entry

        Returns:
            (should_interject, reason, is_test_mode): Tuple of decision, reasoning, and test mode flag
        """
        try:
            if not context:
                return False, "No context provided", False

            current_message = context[-1]["content"]

            # Clean message content if it has IRC nick formatting like "<nick> message"
            message_match = re.search(r"<?\S+>\s*(.*)", current_message)
            if message_match:
                current_message = message_match.group(1).strip()

            # Use full context for better decision making, but specify the current message in prompt
            prompt = self.proactive_config["prompts"]["interject"].format(message=current_message)
            validation_models = self.proactive_config["models"]["validation"]

            final_score = None
            all_responses = []

            for i, model in enumerate(validation_models):
                resp, client, _, _ = await self.agent.model_router.call_raw_with_model(
                    model, context, prompt
                )
                response = client.extract_text_from_response(resp)

                if not response or response.startswith("API error:"):
                    return False, f"No response from validation model {i + 1}", False

                response = response.strip()
                all_responses.append(f"Model {i + 1} ({model}): {response}")

                score_match = re.search(r"(\d+)/10", response)
                if not score_match:
                    logger.warning(
                        "No valid score found in proactive interject response from model %s: %s",
                        i + 1,
                        response,
                    )
                    return False, f"No score found in validation step {i + 1}", False

                score = int(score_match.group(1))
                final_score = score

                logger.debug(
                    f"Proactive validation step {i + 1}/{len(validation_models)} - Model: {model}, Score: {score}"
                )

                threshold = self.proactive_config["interject_threshold"]
                if score < threshold - 1:
                    if i > 0:
                        logger.info(
                            "Proactive interjection rejected at step %s/%s (%s... Score: %s)",
                            i + 1,
                            len(validation_models),
                            current_message[:150],
                            score,
                        )
                    else:
                        logger.debug(
                            "Proactive interjection rejected at step %s/%s (Score: %s)",
                            i + 1,
                            len(validation_models),
                            score,
                        )
                    return (
                        False,
                        f"Rejected at validation step {i + 1} (Score: {score})",
                        False,
                    )

            if final_score is not None:
                threshold = self.proactive_config["interject_threshold"]

                if final_score >= threshold:
                    logger.debug(
                        "Proactive interjection triggered for message: %s... (Final Score: %s)",
                        current_message[:150],
                        final_score,
                    )
                    return True, f"Interjection decision (Final Score: {final_score})", False
                if final_score >= threshold - 1:
                    logger.debug(
                        "Proactive interjection BARELY triggered for message: %s... (Final Score: %s) - SWITCHING TO TEST MODE",
                        current_message[:150],
                        final_score,
                    )
                    return True, f"Barely triggered - test mode (Final Score: {final_score})", True
                return False, f"No interjection (Final Score: {final_score})", False

            return False, "No valid final score", False

        except Exception as e:
            logger.error("Error checking proactive interject: %s", e)
            return False, f"Error: {str(e)}", False

    async def _handle_debounced_proactive_check(
        self,
        msg: RoomMessage,
        reply_sender: Callable[[str], Awaitable[None]],
    ) -> None:
        try:
            if not self.proactive_rate_limiter.check_limit():
                logger.debug(
                    "Proactive interjection rate limit exceeded during debounced check, skipping message from %s",
                    msg.nick,
                )
                return

            context = await self.agent.history.get_context_for_message(
                msg, self.proactive_config["history_size"]
            )
            should_interject, reason, forced_test_mode = await self.should_interject_proactively(
                context
            )
            if not should_interject:
                return

            channel_key = self.command_resolver.channel_key(msg.server_tag, msg.channel_name)
            classified_label = await self.classify_mode(context)
            classified_trigger = self.command_resolver.trigger_for_label(classified_label)
            classified_mode_key, classified_runtime = self.command_resolver.runtime_for_trigger(
                classified_trigger
            )
            if classified_mode_key != "serious":
                test_channels = self.agent.config.get("behavior", {}).get(
                    "proactive_interjecting_test", []
                )
                is_test_channel = test_channels and channel_key in test_channels
                mode_desc = "[TEST MODE] " if is_test_channel else ""
                logger.warning(
                    "%sProactive interjection suggested but not serious mode: %s (%s). Reason: %s",
                    mode_desc,
                    classified_label,
                    classified_trigger,
                    reason,
                )
                return

            test_channels = self.agent.config.get("behavior", {}).get(
                "proactive_interjecting_test", []
            )
            is_test_channel = test_channels and channel_key in test_channels
            if is_test_channel or forced_test_mode:
                test_reason = "[BARELY TRIGGERED]" if forced_test_mode else "[TEST CHANNEL]"
                logger.info(
                    "[TEST MODE] %s Would interject proactively for message from %s in %s: %s... Reason: %s",
                    test_reason,
                    msg.nick,
                    msg.channel_name,
                    msg.content[:150],
                    reason,
                )
                send_message = False
            else:
                logger.info(
                    "Interjecting proactively for message from %s in %s: %s... Reason: %s",
                    msg.nick,
                    msg.channel_name,
                    msg.content[:150],
                    reason,
                )
                send_message = True

            agent_result = await self._run_actor(
                context,
                msg.mynick,
                mode="serious",
                reasoning_effort=classified_runtime["reasoning_effort"],
                model=self.proactive_config["models"]["serious"],
                extra_prompt=" " + self.proactive_config["prompts"]["serious_extra"],
                arc=msg.arc,
                secrets=msg.secrets,
            )

            if not agent_result or not agent_result.text or agent_result.text.startswith("Error: "):
                logger.info("Agent decided not to interject proactively for %s", msg.channel_name)
                return

            response_text = self._clean_response_text(agent_result.text, msg.nick)
            if send_message:
                response_text = f"[{model_str_core(self.proactive_config['models']['serious'])}] {response_text}"
                logger.info(
                    "Sending proactive agent (%s/%s) response to %s: %s",
                    classified_label,
                    classified_trigger,
                    msg.channel_name,
                    response_text,
                )
                await reply_sender(response_text)
                response_msg = dataclasses.replace(msg, nick=msg.mynick, content=response_text)
                await self.agent.history.add_message(response_msg, mode=classified_trigger)
                await self.autochronicler.check_and_chronicle(
                    msg.mynick,
                    msg.server_tag,
                    msg.channel_name,
                    self.command_config["history_size"],
                )
            else:
                logger.info(
                    "[TEST MODE] Generated proactive response for %s: %s",
                    msg.channel_name,
                    response_text,
                )
        except Exception as e:
            logger.error("Error in debounced proactive check for %s: %s", msg.channel_name, e)

    async def _run_actor(
        self,
        context: list[dict[str, str]],
        mynick: str,
        *,
        mode: str,
        extra_prompt: str = "",
        model: str | list[str] | None = None,
        no_context: bool = False,
        secrets: dict[str, Any] | None = None,
        steering_message_provider: Callable[[], Awaitable[list[dict[str, str]]]] | None = None,
        **actor_kwargs,
    ) -> AgentResult | None:
        mode_cfg = self.command_config["modes"][mode].copy()
        if no_context:
            context = context[-1:]
            mode_cfg["include_chapter_summary"] = False
        elif mode_cfg.get("auto_reduce_context") and len(context) > 1:
            mode_cfg["reduce_context"] = True

        model_override = model if isinstance(model, str) else None
        system_prompt = self.build_system_prompt(mode, mynick, model_override) + extra_prompt

        try:
            agent_result = await self.agent.run_actor(
                context,
                mode_cfg=mode_cfg,
                system_prompt=system_prompt,
                model=model,
                secrets=secrets,
                steering_message_provider=steering_message_provider,
                **actor_kwargs,
            )
        except Exception as e:
            logger.error("Error during agent execution: %s", e, exc_info=True)
            return AgentResult(
                text=f"Error: {e}",
                total_input_tokens=None,
                total_output_tokens=None,
                total_cost=None,
                tool_calls_count=0,
                primary_model=None,
            )

        if agent_result is None:
            return None

        response_text = agent_result.text
        max_response_bytes = self._response_max_bytes()
        if response_text and len(response_text.encode("utf-8")) > max_response_bytes:
            logger.info(
                "Response too long (%s bytes, max %s), creating artifact",
                len(response_text.encode("utf-8")),
                max_response_bytes,
            )
            response_text = await self._long_response_to_artifact(response_text)
        if response_text:
            response_text = response_text.strip()

        return dataclasses.replace(agent_result, text=response_text)

    async def _long_response_to_artifact(self, full_response: str) -> str:
        from ..agentic_actor.tools import ShareArtifactExecutor

        executor = ShareArtifactExecutor.from_config(self.agent.config)
        artifact_result = await executor.execute(full_response)
        artifact_url = artifact_result.split("Artifact shared: ")[1].strip()

        max_response_bytes = self._response_max_bytes()

        # Trim to fit byte limit while respecting character boundaries
        trimmed = full_response
        while len(trimmed.encode("utf-8")) > max_response_bytes and trimmed:
            trimmed = trimmed[:-1]

        # Try to break at end of sentence or word for cleaner output
        min_len = max(0, len(trimmed) - 100)
        last_sentence = trimmed.rfind(".")
        last_word = trimmed.rfind(" ")
        if last_sentence > min_len:
            trimmed = trimmed[: last_sentence + 1]
        elif last_word > min_len:
            trimmed = trimmed[:last_word]

        trimmed += f"... full response: {artifact_url}"

        return trimmed

    async def handle_command(
        self,
        msg: RoomMessage,
        trigger_message_id: int,
        reply_sender: Callable[[str], Awaitable[None]],
    ) -> None:
        # Cancel pending proactive checks immediately when explicit command arrives.
        await self.proactive_debouncer.cancel_channel(
            self.command_resolver.channel_key(msg.server_tag, msg.channel_name)
        )

        if self.command_resolver.should_bypass_steering_queue(msg):
            await self._handle_command_core(
                msg,
                trigger_message_id,
                reply_sender,
                self.steering_queue.key_for_message(msg),
            )
            return

        await self._run_or_queue_command(msg, trigger_message_id, reply_sender)

    async def _handle_command_core(
        self,
        msg: RoomMessage,
        trigger_message_id: int,
        reply_sender: Callable[[str], Awaitable[None]],
        steering_key: SteeringKey,
    ) -> None:
        if not self.rate_limiter.check_limit():
            logger.warning("Rate limiting triggered for %s", msg.nick)
            rate_msg = f"{msg.nick}: Slow down a little, will you? (rate limiting)"
            await reply_sender(rate_msg)
            response_msg = dataclasses.replace(msg, nick=msg.mynick, content=rate_msg)
            await self.agent.history.add_message(response_msg)
            return

        logger.info(
            "Received command from %s on %s/%s: %s",
            msg.nick,
            msg.server_tag,
            msg.channel_name,
            msg.content,
        )

        # Work with fixed context from now on to avoid debouncing/classification races!
        default_size = self.command_config["history_size"]
        max_size = max(
            default_size,
            *(mode.get("history_size", 0) for mode in self.command_config["modes"].values()),
        )
        context = await self.agent.history.get_context_for_message(msg, max_size)

        # Debounce briefly to consolidate quick followups e.g. due to automatic IRC message splits
        debounce = self.command_config.get("debounce", 0)
        if debounce > 0:
            original_timestamp = time.time()
            await asyncio.sleep(debounce)

            followups = await self.agent.history.get_recent_messages_since(
                msg.server_tag,
                msg.channel_name,
                msg.nick,
                original_timestamp,
                thread_id=msg.thread_id,
            )
            if followups:
                logger.debug("Debounced %s followup messages from %s", len(followups), msg.nick)
                context[-1]["content"] += "\n" + "\n".join([m["message"] for m in followups])

        resolved = await self.command_resolver.resolve(
            msg=msg,
            context=context,
            default_size=default_size,
        )
        await self._route_command(
            msg,
            context,
            trigger_message_id,
            reply_sender,
            steering_key=steering_key,
            resolved=resolved,
        )
        await self.proactive_debouncer.cancel_channel(
            self.command_resolver.channel_key(msg.server_tag, msg.channel_name)
        )
        await self.autochronicler.check_and_chronicle(
            msg.mynick, msg.server_tag, msg.channel_name, default_size
        )

    async def _run_or_queue_command(
        self,
        msg: RoomMessage,
        trigger_message_id: int,
        reply_sender: Callable[[str], Awaitable[None]],
    ) -> None:
        """Run a steering-queue command, becoming the session runner if first.

        Single loop processes both commands and compacted passive tails.
        The lock is held only for brief queue mutation inside
        _take_next_work_compacted(); long async handling runs unlocked,
        so new items may arrive while processing. The loop naturally
        re-checks after each item â€” no inner loop needed.
        """
        (
            is_runner,
            steering_key,
            active_item,
        ) = await self.steering_queue.enqueue_command_or_start_runner(
            msg,
            trigger_message_id,
            reply_sender,
        )

        if not is_runner:
            await active_item.completion
            return

        try:
            while active_item is not None:
                if active_item.kind == "command":
                    assert active_item.trigger_message_id is not None
                    await self._handle_command_core(
                        active_item.msg,
                        active_item.trigger_message_id,
                        active_item.reply_sender,
                        steering_key,
                    )
                else:
                    await self._handle_passive_message_core(
                        active_item.msg,
                        active_item.reply_sender,
                    )
                self.steering_queue.finish_item(active_item)

                dropped, active_item = await self.steering_queue.take_next_work_compacted(
                    steering_key
                )
                for item in dropped:
                    self.steering_queue.finish_item(item)
        except Exception as e:
            await self.steering_queue.abort_session(steering_key, e)
            if active_item is not None:
                self.steering_queue.fail_item(active_item, e)
            raise

    async def handle_passive_message(
        self,
        msg: RoomMessage,
        reply_sender: Callable[[str], Awaitable[None]],
    ) -> None:
        queued_item = await self.steering_queue.enqueue_passive_if_session_exists(msg, reply_sender)

        if queued_item is None:
            await self._handle_passive_message_core(msg, reply_sender)
            return

        await queued_item.completion

    async def _handle_passive_message_core(
        self,
        msg: RoomMessage,
        reply_sender: Callable[[str], Awaitable[None]],
    ) -> None:
        channel_key = self.command_resolver.channel_key(msg.server_tag, msg.channel_name)
        if (
            channel_key
            in self.proactive_config["interjecting"] + self.proactive_config["interjecting_test"]
        ):
            await self.proactive_debouncer.schedule_check(
                msg,
                channel_key,
                reply_sender,
                self._handle_debounced_proactive_check,
            )

        max_size = self.command_config["history_size"]
        await self.autochronicler.check_and_chronicle(
            msg.mynick, msg.server_tag, msg.channel_name, max_size
        )

    async def _route_command(
        self,
        msg: RoomMessage,
        context: list[dict[str, str]],
        trigger_message_id: int,
        reply_sender: Callable[[str], Awaitable[None]],
        steering_key: SteeringKey,
        resolved: ResolvedCommand,
    ) -> None:
        if resolved.error:
            logger.warning(
                "Command parse error from %s: %s (%s)", msg.nick, resolved.error, msg.content
            )
            await reply_sender(f"{msg.nick}: {resolved.error}")
            return

        if resolved.help_requested:
            logger.debug("Sending help message to %s", msg.nick)
            help_msg = self.command_resolver.build_help_message(msg.server_tag, msg.channel_name)
            await reply_sender(help_msg)
            response_msg = dataclasses.replace(msg, nick=msg.mynick, content=help_msg)
            await self.agent.history.add_message(response_msg)
            return

        if resolved.model_override:
            logger.debug("Overriding model to %s", resolved.model_override)

        assert resolved.selected_trigger is not None
        assert resolved.selected_label is not None
        assert resolved.mode_key is not None
        assert resolved.runtime is not None

        selected_trigger = resolved.selected_trigger
        selected_label = resolved.selected_label
        mode_key = resolved.mode_key
        runtime = resolved.runtime
        no_context = resolved.no_context

        if resolved.selected_automatically:
            logger.debug(
                "Processing automatic mode request from %s: %s",
                msg.nick,
                resolved.query_text,
            )
            if resolved.channel_mode is not None:
                logger.debug(
                    "Channel policy %s resolved as %s -> %s",
                    resolved.channel_mode,
                    selected_label,
                    selected_trigger,
                )
        else:
            logger.debug(
                "Processing explicit trigger %s (%s) from %s: %s",
                selected_trigger,
                mode_key,
                msg.nick,
                resolved.query_text,
            )

        steering_enabled = bool(runtime["steering"]) and not no_context

        async def steering_message_provider() -> list[dict[str, str]]:
            if not steering_enabled:
                return []
            return await self.steering_queue.drain_steering_context_messages(steering_key)

        async def progress_cb(text: str) -> None:
            await reply_sender(text)
            response_msg = dataclasses.replace(msg, nick=msg.mynick, content=text)
            await self.agent.history.add_message(response_msg)

        async def persistence_cb(text: str) -> None:
            response_msg = dataclasses.replace(msg, nick=msg.mynick, content=text)
            await self.agent.history.add_message(
                response_msg, content_template="[internal monologue] {message}"
            )

        run_kwargs: dict[str, Any] = {
            "mode": mode_key,
            "reasoning_effort": runtime["reasoning_effort"],
            "progress_callback": progress_cb,
            "persistence_callback": persistence_cb,
            "arc": msg.arc,
            "no_context": no_context,
            "model": resolved.model_override or runtime["model"],
            "secrets": msg.secrets,
            "steering_message_provider": steering_message_provider,
        }
        if runtime["allowed_tools"] is not None:
            run_kwargs["allowed_tools"] = runtime["allowed_tools"]

        agent_result = await self._run_actor(
            context[-runtime["history_size"] :],
            msg.mynick,
            **run_kwargs,
        )

        if agent_result and agent_result.text:
            response_text = self._clean_response_text(agent_result.text, msg.nick)
            cost_str = f"${agent_result.total_cost:.4f}" if agent_result.total_cost else "?"
            logger.info(
                "Sending %s/%s response (%s) to %s: %s",
                selected_label,
                selected_trigger,
                cost_str,
                msg.channel_name,
                response_text,
            )

            llm_call_id = None
            if agent_result.primary_model:
                try:
                    spec = parse_model_spec(agent_result.primary_model)
                    llm_call_id = await self.agent.history.log_llm_call(
                        provider=spec.provider,
                        model=spec.name,
                        input_tokens=agent_result.total_input_tokens,
                        output_tokens=agent_result.total_output_tokens,
                        cost=agent_result.total_cost,
                        call_type="agent_run",
                        arc_name=msg.arc,
                        trigger_message_id=trigger_message_id,
                    )
                except ValueError:
                    logger.warning("Could not parse model spec: %s", agent_result.primary_model)

            await reply_sender(response_text)
            response_msg = dataclasses.replace(msg, nick=msg.mynick, content=response_text)
            response_message_id = await self.agent.history.add_message(
                response_msg,
                mode=selected_trigger,
                llm_call_id=llm_call_id,
            )
            if llm_call_id:
                await self.agent.history.update_llm_call_response(llm_call_id, response_message_id)

            if agent_result.total_cost and agent_result.total_cost > 0.2:
                in_tokens = agent_result.total_input_tokens or 0
                out_tokens = agent_result.total_output_tokens or 0
                cost_msg = (
                    f"(this message used {agent_result.tool_calls_count} tool calls, "
                    f"{in_tokens} in / {out_tokens} out tokens, "
                    f"and cost ${agent_result.total_cost:.4f})"
                )
                logger.info("Cost followup for %s: %s", msg.channel_name, cost_msg)
                await reply_sender(cost_msg)
                response_msg = dataclasses.replace(msg, nick=msg.mynick, content=cost_msg)
                await self.agent.history.add_message(response_msg)

            if agent_result.total_cost:
                cost_before = await self.agent.history.get_arc_cost_today(msg.arc)
                cost_before -= agent_result.total_cost
                dollars_before = int(cost_before)
                dollars_after = int(cost_before + agent_result.total_cost)
                if dollars_after > dollars_before:
                    total_today = cost_before + agent_result.total_cost
                    fun_msg = f"(fun fact: my messages in this channel have already cost ${total_today:.4f} today)"
                    logger.info("Daily cost milestone for %s: %s", msg.arc, fun_msg)
                    await reply_sender(fun_msg)
                    response_msg = dataclasses.replace(msg, nick=msg.mynick, content=fun_msg)
                    await self.agent.history.add_message(response_msg)
        else:
            logger.info(
                "Agent in %s/%s mode chose not to answer for %s",
                selected_label,
                selected_trigger,
                msg.channel_name,
            )
